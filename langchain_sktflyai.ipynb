{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMadLFLRyuM2mVie6esa0YS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tiabet/NLP/blob/master/langchain_sktflyai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Co4HyITVIRGq",
        "outputId": "847b4bd0-68a4-4877-afaf-253a31431100"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.39.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Downloading openai-1.39.0-py3-none-any.whl (336 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.7/336.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.39.0\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.2.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.0)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.27 (from langchain)\n",
            "  Downloading langchain_core-0.2.28-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.96-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.27->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (4.12.2)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Downloading langchain-0.2.12-py3-none-any.whl (990 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.6/990.6 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.28-py3-none-any.whl (379 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.9/379.9 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.96-py3-none-any.whl (140 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.1/140.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: tenacity, orjson, jsonpointer, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.12 langchain-core-0.2.28 langchain-text-splitters-0.2.2 langsmith-0.1.96 orjson-3.10.6 tenacity-8.5.0\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.10/dist-packages (0.2.28)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.10.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.12)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.96)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.12->langchain-community) (0.2.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.2.11-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain-community-0.2.11 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install langchain\n",
        "!pip install langchain-community langchain-core\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = '64650e80fc9f42d28849c6a5f601d832'\n",
        "os.environ[\"OPENAI_API_TYPE\"] = 'azure'\n",
        "os.environ[\"OPENAI_API_VERSION\"] = '2023-05-15'\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://sktflyai.openai.azure.com/\""
      ],
      "metadata": {
        "id": "qG1fS94VJpcR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import AzureOpenAI\n",
        "\n",
        "llm = AzureOpenAI(deployment_name=\"dev-davinci-002\")\n",
        "llm.invoke(\"Tell me a joke\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "Yv2iVoBkJ0sZ",
        "outputId": "fcdf588e-63f8-40fa-ba0b-9ffed80dba47"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'.\" I said, \"I\\'ll tell you a joke.\" \"I\\'ll tell you a joke.\" I said, \"I\\'ll tell you a joke.\" But it wasn\\'t a joke. I said, \"This is a joke.\" I said, \"I\\'ll tell you a joke.\" I said, \"I\\'ll tell you a joke.\" I said, \"I\\'ll tell you a joke.\" I said, \"I\\'ll tell you a joke.\" \"You\\'re making fun of Islam.\" \"You\\'re making fun of Islam.\" \"You\\'re making fun of Islam.\" \"You\\'re making fun of Islam.\" \"You\\'re making fun of Islam.\" \"You\\'re making fun of Islam.\" \"You\\'re making fun of Islam.\" \"You\\'re making fun of Islam.\" \"You\\'re making fun of Islam.\" \"You\\'re making fun of Islam I want to tell you a joke.\" \"I want to tell you a joke.\" \"I want to tell you a joke.\" \"I want to tell you a joke.\" \"I want to tell you a joke.\" \"I want to tell you a joke.\" \"I want to tell you a joke.\" \"I want to tell you a joke.\" \"I want to tell you a joke.\" \"I want to tell you'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = AzureOpenAI(deployment_name=\"dev-gpt-35-turbo-instruct\")\n",
        "llm.invoke(\"Tell me a joke with a Korean. Answer the Korean\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MXibrw1-L_oV",
        "outputId": "9a336f42-5f63-4f64-9c88-582a5accb4d3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' man asked the American man, \"Why was the math book sad?\" The American man replied, \"I don\\'t know, why?\" The Korean man responded, \"Because it had too many problems.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import AzureChatOpenAI\n",
        "\n",
        "chat = AzureChatOpenAI(deployment_name=\"dev-gpt-35-turbo\")\n",
        "chat.invoke(\"Tell me a joke. Answer the Korean\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mla0FeWcM1Rn",
        "outputId": "9d2521db-cf8a-46be-c54e-667ce1d48e90"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='왜 토끼는 주머니에 당근을 가지고 다니나요? \\n- 당근이 많이 담겨있기 때문에!', response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 15, 'total_tokens': 64}, 'model_name': 'gpt-35-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-759b3e49-e725-4f2c-8b8c-c4f81b18c540-0')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "\n",
        "chat = AzureChatOpenAI(deployment_name=\"dev-gpt-35-turbo\", streaming=True, callbacks=[StreamingStdOutCallbackHandler()])\n",
        "chat.invoke(\"파이썬과 자바 중 더 인기 있는 언어는 뭐야? 그 이유를 3개로 정리해줘\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDyCbSW9UmGa",
        "outputId": "90f62f22-e9c9-4a82-ce03-3138bfd31004"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. 파이썬은 간편하고 배우기 쉬운 언어이다. 파이썬은 문법이 간결하고 가독성이 좋아서 초보자도 쉽게 배울 수 있다. 또한, 파이썬은 인터프리터 언어로 코드를 작성하고 즉시 실행하여 결과를 확인할 수 있다는 장점이 있다.\n",
            "\n",
            "2. 파이썬은 다양한 분야에서 활용될 수 있다. 파이썬은 데이터 분석, 인공지능, 웹 개발 등 다양한 분야에서 사용되는 언어로 인기가 많다. 특히, 데이터 분석과 인공지능 분야에서는 다양한 라이브러리와 툴이 제공되어 있어 효율적인 작업을 할 수 있다.\n",
            "\n",
            "3. 파이썬은 개발 생산성이 높다. 파이썬은 간결한 문법과 다양한 라이브러리를 제공하여 개발 생산성을 높일 수 있다. 또한, 파이썬은 다른 언어와의 통합이 용이하고 개발자들 간의 협업이 원활하게 이루어질 수 있는 환경을 제공한다. 이는 개발 프로젝트의 효율성을 높여주는 요소로 작용한다."
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='1. 파이썬은 간편하고 배우기 쉬운 언어이다. 파이썬은 문법이 간결하고 가독성이 좋아서 초보자도 쉽게 배울 수 있다. 또한, 파이썬은 인터프리터 언어로 코드를 작성하고 즉시 실행하여 결과를 확인할 수 있다는 장점이 있다.\\n\\n2. 파이썬은 다양한 분야에서 활용될 수 있다. 파이썬은 데이터 분석, 인공지능, 웹 개발 등 다양한 분야에서 사용되는 언어로 인기가 많다. 특히, 데이터 분석과 인공지능 분야에서는 다양한 라이브러리와 툴이 제공되어 있어 효율적인 작업을 할 수 있다.\\n\\n3. 파이썬은 개발 생산성이 높다. 파이썬은 간결한 문법과 다양한 라이브러리를 제공하여 개발 생산성을 높일 수 있다. 또한, 파이썬은 다른 언어와의 통합이 용이하고 개발자들 간의 협업이 원활하게 이루어질 수 있는 환경을 제공한다. 이는 개발 프로젝트의 효율성을 높여주는 요소로 작용한다.', response_metadata={'finish_reason': 'stop'}, id='run-319535d2-ec00-41e6-958e-95c051513c21-0')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
        "\n",
        "messages = [SystemMessage(content=\"You are a professional translator.\"),\n",
        "    HumanMessage(content=\"파이썬과 자바 중 더 인기 있는 언어는 뭐야? 그 이유를 3개로 정리해서 영어로 번역해줘\")]\n",
        "chat = AzureChatOpenAI(deployment_name=\"dev-gpt-35-turbo\", streaming=True, callbacks=[StreamingStdOutCallbackHandler()])\n",
        "chat(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-_gU9DnV0r3",
        "outputId": "76b7e5ab-af74-4572-8872-b57a36495603"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Which language is more popular, Python or Java? Please translate the reasons into English and summarize them into three points."
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Which language is more popular, Python or Java? Please translate the reasons into English and summarize them into three points.', response_metadata={'finish_reason': 'stop'}, id='run-a19f7a96-1d9e-4c5b-b749-86ab68be3006-0')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [SystemMessage(content=\"당신은 공부 계획을 알려주는 스터디 플래너이다. 주제를 입력받으면 공부 계획을 알려줘.\"),\n",
        "    HumanMessage(content=\"Large Language Model을 공부하고 싶어.\")]\n",
        "chat = AzureChatOpenAI(deployment_name=\"dev-gpt-35-turbo\", streaming=True, callbacks=[StreamingStdOutCallbackHandler()])\n",
        "chat.invoke(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBgSM848Wvw1",
        "outputId": "d31447d0-149c-4721-ba4c-c489b10bfeae"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Large Language Model을 공부하기 위한 계획을 제안해드리겠습니다.\n",
            "\n",
            "1. 기본 개념 이해하기:\n",
            "   - Large Language Model이란 무엇인지, 어떻게 작동하는지에 대한 기본 개념을 학습해야 합니다. 관련된 논문이나 자료를 찾아 읽어보세요.\n",
            "\n",
            "2. 사전 지식 습득:\n",
            "   - Natural Language Processing (자연어 처리)와 Machine Learning (머신 러닝)에 대한 사전 지식이 필요합니다. 이를 위해 관련된 책이나 강의를 찾아보세요.\n",
            "\n",
            "3. 데이터셋 탐색:\n",
            "   - Large Language Model을 학습시키기 위한 데이터셋을 찾아보세요. 오픈 데이터셋이나 코퍼스를 활용할 수 있습니다.\n",
            "\n",
            "4. 모델 학습:\n",
            "   - PyTorch, TensorFlow 등의 프레임워크를 사용하여 Large Language Model을 구축하고 학습시키세요. 관련된 튜토리얼이나 예제 코드를 참고할 수 있습니다.\n",
            "\n",
            "5. 모델 평가:\n",
            "   - 학습된 모델의 성능을 평가해보세요. 퍼플렉서티나 BLEU score 등을 사용하여 평가할 수 있습니다.\n",
            "\n",
            "6. 실제 응용:\n",
            "   - Large Language Model을 활용하여 실제 자연어 처리 태스크에 적용해보세요. 예를 들어, 자동 완성, 기계 번역, 질의 응답 시스템 등을 구현해볼 수 있습니다.\n",
            "\n",
            "7. 연구 동향 및 논문 리뷰:\n",
            "   - Large Language Model 관련 연구 동향을 파악하고, 관련 논문들을 읽고 리뷰해보세요. 이를 통해 최신 기술 동향을 파악할 수 있습니다.\n",
            "\n",
            "8. 프로젝트 구현:\n",
            "   - Large Language Model을 활용한 프로젝트를 진행해보세요. 예를 들어, 챗봇 시스템, 문서 요약 등을 구현해볼 수 있습니다.\n",
            "\n",
            "이러한 계획을 따라가면서 Large Language Model에 대한 이해를 높이고 실제 응용을 통해 실력을 향상시킬 수 있을 것입니다. 계획을 세우고 일정을 관리하여 체계적으로 학습을 진행해보세요. 힘내시기 바랍니다!"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Large Language Model을 공부하기 위한 계획을 제안해드리겠습니다.\\n\\n1. 기본 개념 이해하기:\\n   - Large Language Model이란 무엇인지, 어떻게 작동하는지에 대한 기본 개념을 학습해야 합니다. 관련된 논문이나 자료를 찾아 읽어보세요.\\n\\n2. 사전 지식 습득:\\n   - Natural Language Processing (자연어 처리)와 Machine Learning (머신 러닝)에 대한 사전 지식이 필요합니다. 이를 위해 관련된 책이나 강의를 찾아보세요.\\n\\n3. 데이터셋 탐색:\\n   - Large Language Model을 학습시키기 위한 데이터셋을 찾아보세요. 오픈 데이터셋이나 코퍼스를 활용할 수 있습니다.\\n\\n4. 모델 학습:\\n   - PyTorch, TensorFlow 등의 프레임워크를 사용하여 Large Language Model을 구축하고 학습시키세요. 관련된 튜토리얼이나 예제 코드를 참고할 수 있습니다.\\n\\n5. 모델 평가:\\n   - 학습된 모델의 성능을 평가해보세요. 퍼플렉서티나 BLEU score 등을 사용하여 평가할 수 있습니다.\\n\\n6. 실제 응용:\\n   - Large Language Model을 활용하여 실제 자연어 처리 태스크에 적용해보세요. 예를 들어, 자동 완성, 기계 번역, 질의 응답 시스템 등을 구현해볼 수 있습니다.\\n\\n7. 연구 동향 및 논문 리뷰:\\n   - Large Language Model 관련 연구 동향을 파악하고, 관련 논문들을 읽고 리뷰해보세요. 이를 통해 최신 기술 동향을 파악할 수 있습니다.\\n\\n8. 프로젝트 구현:\\n   - Large Language Model을 활용한 프로젝트를 진행해보세요. 예를 들어, 챗봇 시스템, 문서 요약 등을 구현해볼 수 있습니다.\\n\\n이러한 계획을 따라가면서 Large Language Model에 대한 이해를 높이고 실제 응용을 통해 실력을 향상시킬 수 있을 것입니다. 계획을 세우고 일정을 관리하여 체계적으로 학습을 진행해보세요. 힘내시기 바랍니다!', response_metadata={'finish_reason': 'stop'}, id='run-5749d3d4-088b-4f2c-ba01-374e9905b084-0')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iLmTQagjYgDt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}